{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**本周只有一个代码实践题**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码用来加载 预先训练好的模型, 你需要只需要修改模型的存放路径即可（第二行代码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步 使用以下链接下载相应预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://convaisharables.blob.core.windows.net/lsp/multiref/small_ft.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "weights = torch.load('../../../small_ft.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_config = GPT2Config(n_embd = 768,n_layer = 12, n_head = 12)\n",
    "model = GPT2LMHeadModel(small_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0699, -0.0288,  0.0483,  ..., -0.1614, -0.0889, -0.0199],\n",
       "        [ 0.0178, -0.0233,  0.0382,  ...,  0.0812,  0.0011,  0.0409],\n",
       "        [-0.1228,  0.0519,  0.1614,  ...,  0.0985, -0.1012, -0.0801],\n",
       "        ...,\n",
       "        [-0.0721, -0.0417,  0.0161,  ...,  0.0179,  0.0231, -0.0108],\n",
       "        [ 0.1482, -0.0124, -0.0164,  ..., -0.1356,  0.1014, -0.0580],\n",
       "        [ 0.0171, -0.0199,  0.0471,  ...,  0.0025,  0.0728,  0.1221]],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights['lm_head.weight'] = weights['lm_head.decoder.weight']\n",
    "weights.pop('lm_head.decoder.weight',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(weights)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你需要写一个推理函数，这个函数接收一个英文句子为输入，输出一个回应。\n",
    "\n",
    "(Enter Codes Down Below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 220, 716, 257, 922, 2933, 764]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"   I  am a good boy .  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    with open(file,'r',encoding='utf8') as data:\n",
    "        lines = [l.strip() for l in data]\n",
    "    dials = []\n",
    "    for l in lines:\n",
    "#         if l == '<dial>':\n",
    "#             dial = []\n",
    "#         elif l == '</dial>':\n",
    "#             dials += [dial]\n",
    "        dials += [[i.strip() for i in l.strip().split(\"__eou__\") if i != \"\"]]\n",
    "    return dials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = '../../../13第十三课 检索系统 对话系统实例实践与分析/lesson_13代码数据1.txt'\n",
    "train_data2 = '../../../13第十三课 检索系统 对话系统实例实践与分析/lesson_13代码数据2.txt'\n",
    "train_data3 = '../../../13第十三课 检索系统 对话系统实例实践与分析/lesson_13代码数据3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "dials1 = read_data(train_data1)\n",
    "dials2 = read_data(train_data2)\n",
    "dials3 = read_data(train_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11118, 1000)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dials1), len(dials2), len(dials3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "dials = dials3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeature(object):\n",
    "    def __init__(self,input_ids,position_ids,token_type_ids,\n",
    "                lm_labels=None,input_len=None):\n",
    "        \n",
    "        self.input_ids = input_ids\n",
    "        self.position_ids = position_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.lm_lanels =lm_labels\n",
    "        if input_len is None:\n",
    "            self.input_len = len(input_ids)\n",
    "        else:\n",
    "            self.input_len = input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,dials,max_len = 1024):\n",
    "        self.max_len = max_len\n",
    "        self.features = build_input_feature(dials)\n",
    "    \n",
    "    def __getitem__(slef,i):\n",
    "        feat_dict = self.features[i]\n",
    "        if self.max_len is not None and feat_dict['input_len'] > self.max_len:\n",
    "            feat_dict['input_ids'] = feat_dict['input_dis'][-self.max_len:]\n",
    "            feat_dict['position_ids'] = feat_dict['position_ids'][-self.max_len:]\n",
    "            feat_dict['token_type_ids'] = feat_dict['token_type_ids'][-self.max_len:]\n",
    "            feat_dict['lm_labels'] = feat_dict['lm_labels'][-self.max_len:]\n",
    "        feat = InputFeaturet(**feat_dict)\n",
    "        return feat\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_input_feature(dials,end_text='<|endoftext|>'):\n",
    "        '''\n",
    "        此函数将对话文本信息输入，然后输出数字化的特征信息，包括input_id,position_id,token_type_id,lm_label,input_len\n",
    "        '''\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        feature = []\n",
    "        for dial in dials:\n",
    "            '''\n",
    "            对于每一个篇对话：\n",
    "            \n",
    "            inputs：        把第一句到倒数第二句话中所有token的index当作inputs输入，\n",
    "            lm_labels：     lm_标注，inputs为-1，outputs为每个词语的token_id\n",
    "            token_type_ids：token类型标注，inputs为0，outputs为1\n",
    "            input_ids：     输入ids：输入token_ids + 输出token_ids（中间带<|endoftext|>分隔符）\n",
    "            input_len：     输入ids的长度\n",
    "            position_ids：  位置id（0 - n）\n",
    "            '''\n",
    "            inputs = sum([tokenizer.encode(u) for u in dial[:-1]],[]) # sum的start参数可以作为一个起始类型，[]则代表列表相加\n",
    "            lm_labels = [-1]*len(inputs) + tokenizer.encode(dial[-1] + end_text) \n",
    "            token_type_ids = [0] * len(inputs) + [1.0] * (len(tokenizer.encode(dial[-1] + end_text)))\n",
    "            input_ids = inputs + tokenizer.encode(end_text + dial[-1])\n",
    "            input_len = len(input_ids)\n",
    "            position_ids = list(range(len(input_ids)))\n",
    "            \n",
    "            feat_dict = {'input_ids':input_ids,\n",
    "                        'position_ids':position_ids,\n",
    "                        'token_type_ids':token_type_ids,\n",
    "                        'lm_labels':lm_labels,\n",
    "                        'input_len':input_len}\n",
    "            feature.append(feat_dict)\n",
    "        return feature\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate(features):\n",
    "        '''\n",
    "        转换为torch.tensor并做padding\n",
    "        '''\n",
    "        inputs_ids = pad_sequence([torch.tensor(f['input_ids'], dtype=torch.long)\n",
    "                                  for f in features],batch_first=True,padding_value=0)\n",
    "        \n",
    "        position_ids = pad_sequence([torch.tensor(f['position_ids'], dtype=torch.long)\n",
    "                                   for f in features],batch_first=True,padding_value=0)\n",
    "        \n",
    "        token_type_ids = pad_sequence([torch.tensor(f['token_type_ids'], dtype=torch.long)\n",
    "                                      for f in features],batch_first=True,padding_value=0)\n",
    "        \n",
    "        labels = pad_sequence([torch.tensor(f['lm_labels'], dtype=torch.long)\n",
    "                              for f in features],batch_first=True,padding_value=-1)\n",
    "        \n",
    "        return (inputs_ids,position_ids,token_type_ids,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(以下是一些测试函数功能的代码)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The taxi drivers are on strike again .',\n",
       " 'What for ?',\n",
       " 'They want the government to reduce the price of the gasoline .',\n",
       " 'It is really a hot potato .']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 2,  3, -1, -1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequence([torch.tensor([1,2,3,4], dtype=torch.long),torch.tensor([2,3], dtype=torch.long)], batch_first=True, padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 4 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-797c740f7dfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 4 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "pad_sequence(torch.tensor([[1,2,3,4],[2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[464,\n",
       " 17536,\n",
       " 6643,\n",
       " 389,\n",
       " 319,\n",
       " 5587,\n",
       " 757,\n",
       " 764,\n",
       " 2061,\n",
       " 329,\n",
       " 5633,\n",
       " 2990,\n",
       " 765,\n",
       " 262,\n",
       " 1230,\n",
       " 284,\n",
       " 4646,\n",
       " 262,\n",
       " 2756,\n",
       " 286,\n",
       " 262,\n",
       " 21408,\n",
       " 764]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([tokenizer.encode(u) for u in test[:-1]], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GPT2Dataset.build_input_feature(dials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': [10248,\n",
       "   3329,\n",
       "   837,\n",
       "   15967,\n",
       "   764,\n",
       "   1148,\n",
       "   612,\n",
       "   257,\n",
       "   3331,\n",
       "   1474,\n",
       "   994,\n",
       "   5633,\n",
       "   1858,\n",
       "   318,\n",
       "   530,\n",
       "   764,\n",
       "   642,\n",
       "   7021,\n",
       "   1497,\n",
       "   422,\n",
       "   994,\n",
       "   5633,\n",
       "   5779,\n",
       "   837,\n",
       "   326,\n",
       "   338,\n",
       "   1165,\n",
       "   1290,\n",
       "   13,\n",
       "   6090,\n",
       "   345,\n",
       "   1487,\n",
       "   617,\n",
       "   1637,\n",
       "   329,\n",
       "   502,\n",
       "   5633,\n",
       "   19457,\n",
       "   306,\n",
       "   837,\n",
       "   286,\n",
       "   1781,\n",
       "   764,\n",
       "   1867,\n",
       "   1611,\n",
       "   286,\n",
       "   7395,\n",
       "   423,\n",
       "   345,\n",
       "   1392,\n",
       "   5633,\n",
       "   7112,\n",
       "   33,\n",
       "   764,\n",
       "   2437,\n",
       "   881,\n",
       "   561,\n",
       "   345,\n",
       "   588,\n",
       "   284,\n",
       "   1487,\n",
       "   5633,\n",
       "   50256,\n",
       "   12825,\n",
       "   34071,\n",
       "   13,\n",
       "   4342,\n",
       "   345,\n",
       "   389,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   12825,\n",
       "   34071,\n",
       "   13,\n",
       "   4342,\n",
       "   345,\n",
       "   389,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 70},\n",
       " {'input_ids': [10248,\n",
       "   6672,\n",
       "   764,\n",
       "   770,\n",
       "   318,\n",
       "   16738,\n",
       "   7455,\n",
       "   5486,\n",
       "   837,\n",
       "   4585,\n",
       "   319,\n",
       "   8378,\n",
       "   286,\n",
       "   314,\n",
       "   4339,\n",
       "   764,\n",
       "   1148,\n",
       "   1770,\n",
       "   41272,\n",
       "   1695,\n",
       "   379,\n",
       "   477,\n",
       "   5633,\n",
       "   1212,\n",
       "   318,\n",
       "   1770,\n",
       "   41272,\n",
       "   5486,\n",
       "   837,\n",
       "   16738,\n",
       "   764,\n",
       "   5812,\n",
       "   837,\n",
       "   23748,\n",
       "   5145,\n",
       "   19061,\n",
       "   546,\n",
       "   326,\n",
       "   764,\n",
       "   314,\n",
       "   1101,\n",
       "   655,\n",
       "   4585,\n",
       "   284,\n",
       "   910,\n",
       "   326,\n",
       "   356,\n",
       "   1053,\n",
       "   2722,\n",
       "   534,\n",
       "   649,\n",
       "   26040,\n",
       "   10504,\n",
       "   5172,\n",
       "   422,\n",
       "   25112,\n",
       "   764,\n",
       "   2504,\n",
       "   373,\n",
       "   2068,\n",
       "   5145,\n",
       "   314,\n",
       "   2492,\n",
       "   470,\n",
       "   12451,\n",
       "   340,\n",
       "   1566,\n",
       "   1568,\n",
       "   428,\n",
       "   1285,\n",
       "   764,\n",
       "   5297,\n",
       "   837,\n",
       "   674,\n",
       "   3586,\n",
       "   9021,\n",
       "   423,\n",
       "   2866,\n",
       "   276,\n",
       "   510,\n",
       "   1201,\n",
       "   356,\n",
       "   2067,\n",
       "   1262,\n",
       "   262,\n",
       "   649,\n",
       "   3049,\n",
       "   12,\n",
       "   11659,\n",
       "   1080,\n",
       "   764,\n",
       "   2484,\n",
       "   439,\n",
       "   314,\n",
       "   1282,\n",
       "   287,\n",
       "   290,\n",
       "   2824,\n",
       "   340,\n",
       "   5633,\n",
       "   5574,\n",
       "   356,\n",
       "   460,\n",
       "   3758,\n",
       "   340,\n",
       "   284,\n",
       "   345,\n",
       "   764,\n",
       "   887,\n",
       "   611,\n",
       "   345,\n",
       "   561,\n",
       "   588,\n",
       "   284,\n",
       "   779,\n",
       "   340,\n",
       "   379,\n",
       "   262,\n",
       "   30939,\n",
       "   837,\n",
       "   345,\n",
       "   1183,\n",
       "   761,\n",
       "   284,\n",
       "   4043,\n",
       "   329,\n",
       "   534,\n",
       "   34279,\n",
       "   1271,\n",
       "   764,\n",
       "   44,\n",
       "   27532,\n",
       "   2644,\n",
       "   611,\n",
       "   314,\n",
       "   1282,\n",
       "   287,\n",
       "   290,\n",
       "   2824,\n",
       "   340,\n",
       "   428,\n",
       "   6672,\n",
       "   837,\n",
       "   318,\n",
       "   612,\n",
       "   597,\n",
       "   835,\n",
       "   314,\n",
       "   714,\n",
       "   779,\n",
       "   340,\n",
       "   1909,\n",
       "   5633,\n",
       "   41505,\n",
       "   5003,\n",
       "   318,\n",
       "   1972,\n",
       "   1877,\n",
       "   837,\n",
       "   523,\n",
       "   314,\n",
       "   761,\n",
       "   284,\n",
       "   3197,\n",
       "   617,\n",
       "   1637,\n",
       "   764,\n",
       "   1722,\n",
       "   890,\n",
       "   355,\n",
       "   345,\n",
       "   2222,\n",
       "   534,\n",
       "   4522,\n",
       "   837,\n",
       "   3503,\n",
       "   837,\n",
       "   356,\n",
       "   460,\n",
       "   4691,\n",
       "   345,\n",
       "   625,\n",
       "   262,\n",
       "   3753,\n",
       "   764,\n",
       "   887,\n",
       "   345,\n",
       "   1839,\n",
       "   470,\n",
       "   307,\n",
       "   1498,\n",
       "   284,\n",
       "   779,\n",
       "   262,\n",
       "   30939,\n",
       "   1566,\n",
       "   534,\n",
       "   649,\n",
       "   34279,\n",
       "   1271,\n",
       "   14443,\n",
       "   764,\n",
       "   50256,\n",
       "   40,\n",
       "   766,\n",
       "   764,\n",
       "   3363,\n",
       "   837,\n",
       "   326,\n",
       "   338,\n",
       "   3734,\n",
       "   764,\n",
       "   314,\n",
       "   1183,\n",
       "   307,\n",
       "   612,\n",
       "   379,\n",
       "   1088,\n",
       "   362,\n",
       "   25,\n",
       "   1270,\n",
       "   9114,\n",
       "   764,\n",
       "   4091,\n",
       "   345,\n",
       "   1568,\n",
       "   837,\n",
       "   290,\n",
       "   5176,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196,\n",
       "   197,\n",
       "   198,\n",
       "   199,\n",
       "   200,\n",
       "   201,\n",
       "   202,\n",
       "   203,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   207,\n",
       "   208,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   214,\n",
       "   215,\n",
       "   216,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   40,\n",
       "   766,\n",
       "   764,\n",
       "   3363,\n",
       "   837,\n",
       "   326,\n",
       "   338,\n",
       "   3734,\n",
       "   764,\n",
       "   314,\n",
       "   1183,\n",
       "   307,\n",
       "   612,\n",
       "   379,\n",
       "   1088,\n",
       "   362,\n",
       "   25,\n",
       "   1270,\n",
       "   9114,\n",
       "   764,\n",
       "   4091,\n",
       "   345,\n",
       "   1568,\n",
       "   837,\n",
       "   290,\n",
       "   5176,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 230},\n",
       " {'input_ids': [2061,\n",
       "   24751,\n",
       "   815,\n",
       "   257,\n",
       "   9095,\n",
       "   423,\n",
       "   5633,\n",
       "   1722,\n",
       "   257,\n",
       "   9095,\n",
       "   837,\n",
       "   339,\n",
       "   1276,\n",
       "   423,\n",
       "   14352,\n",
       "   11281,\n",
       "   290,\n",
       "   3303,\n",
       "   4678,\n",
       "   764,\n",
       "   1629,\n",
       "   262,\n",
       "   976,\n",
       "   640,\n",
       "   837,\n",
       "   339,\n",
       "   1276,\n",
       "   423,\n",
       "   922,\n",
       "   8492,\n",
       "   837,\n",
       "   262,\n",
       "   2461,\n",
       "   329,\n",
       "   465,\n",
       "   1693,\n",
       "   290,\n",
       "   16106,\n",
       "   11113,\n",
       "   351,\n",
       "   1854,\n",
       "   764,\n",
       "   6090,\n",
       "   345,\n",
       "   670,\n",
       "   739,\n",
       "   3833,\n",
       "   5633,\n",
       "   921,\n",
       "   760,\n",
       "   837,\n",
       "   661,\n",
       "   1762,\n",
       "   994,\n",
       "   389,\n",
       "   477,\n",
       "   8179,\n",
       "   10908,\n",
       "   1201,\n",
       "   356,\n",
       "   821,\n",
       "   4445,\n",
       "   7533,\n",
       "   764,\n",
       "   50256,\n",
       "   40,\n",
       "   892,\n",
       "   314,\n",
       "   1053,\n",
       "   1392,\n",
       "   973,\n",
       "   284,\n",
       "   670,\n",
       "   739,\n",
       "   3833,\n",
       "   764,\n",
       "   314,\n",
       "   481,\n",
       "   4532,\n",
       "   3589,\n",
       "   284,\n",
       "   262,\n",
       "   2239,\n",
       "   286,\n",
       "   534,\n",
       "   7533,\n",
       "   2952,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   40,\n",
       "   892,\n",
       "   314,\n",
       "   1053,\n",
       "   1392,\n",
       "   973,\n",
       "   284,\n",
       "   670,\n",
       "   739,\n",
       "   3833,\n",
       "   764,\n",
       "   314,\n",
       "   481,\n",
       "   4532,\n",
       "   3589,\n",
       "   284,\n",
       "   262,\n",
       "   2239,\n",
       "   286,\n",
       "   534,\n",
       "   7533,\n",
       "   2952,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 88},\n",
       " {'input_ids': [17250,\n",
       "   837,\n",
       "   922,\n",
       "   3329,\n",
       "   837,\n",
       "   4544,\n",
       "   5633,\n",
       "   644,\n",
       "   460,\n",
       "   314,\n",
       "   1037,\n",
       "   345,\n",
       "   351,\n",
       "   5633,\n",
       "   10248,\n",
       "   3329,\n",
       "   314,\n",
       "   1549,\n",
       "   588,\n",
       "   284,\n",
       "   6920,\n",
       "   428,\n",
       "   3091,\n",
       "   286,\n",
       "   3835,\n",
       "   284,\n",
       "   14119,\n",
       "   764,\n",
       "   11380,\n",
       "   837,\n",
       "   3387,\n",
       "   1234,\n",
       "   340,\n",
       "   319,\n",
       "   428,\n",
       "   5046,\n",
       "   13,\n",
       "   32,\n",
       "   2533,\n",
       "   603,\n",
       "   393,\n",
       "   416,\n",
       "   5417,\n",
       "   5633,\n",
       "   2437,\n",
       "   890,\n",
       "   857,\n",
       "   340,\n",
       "   1011,\n",
       "   284,\n",
       "   3151,\n",
       "   14119,\n",
       "   416,\n",
       "   5417,\n",
       "   5633,\n",
       "   37887,\n",
       "   546,\n",
       "   734,\n",
       "   1227,\n",
       "   764,\n",
       "   2504,\n",
       "   338,\n",
       "   1165,\n",
       "   890,\n",
       "   13,\n",
       "   2437,\n",
       "   890,\n",
       "   857,\n",
       "   340,\n",
       "   1011,\n",
       "   284,\n",
       "   3151,\n",
       "   14119,\n",
       "   416,\n",
       "   1633,\n",
       "   4529,\n",
       "   5633,\n",
       "   8585,\n",
       "   3478,\n",
       "   1528,\n",
       "   764,\n",
       "   6423,\n",
       "   703,\n",
       "   881,\n",
       "   318,\n",
       "   326,\n",
       "   416,\n",
       "   1633,\n",
       "   4529,\n",
       "   5633,\n",
       "   5756,\n",
       "   502,\n",
       "   766,\n",
       "   13,\n",
       "   1026,\n",
       "   705,\n",
       "   264,\n",
       "   7632,\n",
       "   5054,\n",
       "   837,\n",
       "   1160,\n",
       "   16059,\n",
       "   837,\n",
       "   1390,\n",
       "   1687,\n",
       "   764,\n",
       "   2504,\n",
       "   338,\n",
       "   257,\n",
       "   1310,\n",
       "   1643,\n",
       "   5789,\n",
       "   764,\n",
       "   7003,\n",
       "   340,\n",
       "   338,\n",
       "   5789,\n",
       "   284,\n",
       "   3758,\n",
       "   340,\n",
       "   416,\n",
       "   1633,\n",
       "   4529,\n",
       "   837,\n",
       "   340,\n",
       "   338,\n",
       "   20061,\n",
       "   290,\n",
       "   14178,\n",
       "   621,\n",
       "   416,\n",
       "   5417,\n",
       "   764,\n",
       "   40,\n",
       "   4724,\n",
       "   314,\n",
       "   423,\n",
       "   284,\n",
       "   3758,\n",
       "   340,\n",
       "   416,\n",
       "   1633,\n",
       "   4529,\n",
       "   764,\n",
       "   5211,\n",
       "   345,\n",
       "   765,\n",
       "   284,\n",
       "   4155,\n",
       "   262,\n",
       "   10154,\n",
       "   837,\n",
       "   4544,\n",
       "   5633,\n",
       "   5297,\n",
       "   837,\n",
       "   3387,\n",
       "   764,\n",
       "   5492,\n",
       "   6070,\n",
       "   503,\n",
       "   428,\n",
       "   1296,\n",
       "   837,\n",
       "   635,\n",
       "   3387,\n",
       "   3551,\n",
       "   262,\n",
       "   1988,\n",
       "   286,\n",
       "   262,\n",
       "   3709,\n",
       "   287,\n",
       "   428,\n",
       "   2272,\n",
       "   764,\n",
       "   50256,\n",
       "   11380,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   11380,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 179},\n",
       " {'input_ids': [40127,\n",
       "   1904,\n",
       "   502,\n",
       "   837,\n",
       "   17266,\n",
       "   6,\n",
       "   321,\n",
       "   764,\n",
       "   1680,\n",
       "   345,\n",
       "   1560,\n",
       "   502,\n",
       "   810,\n",
       "   262,\n",
       "   16936,\n",
       "   1281,\n",
       "   31810,\n",
       "   318,\n",
       "   5633,\n",
       "   5189,\n",
       "   1781,\n",
       "   764,\n",
       "   1514,\n",
       "   3892,\n",
       "   4058,\n",
       "   764,\n",
       "   6756,\n",
       "   826,\n",
       "   379,\n",
       "   262,\n",
       "   1306,\n",
       "   4675,\n",
       "   764,\n",
       "   921,\n",
       "   1183,\n",
       "   766,\n",
       "   257,\n",
       "   7331,\n",
       "   837,\n",
       "   7872,\n",
       "   2615,\n",
       "   13,\n",
       "   464,\n",
       "   1281,\n",
       "   2607,\n",
       "   318,\n",
       "   319,\n",
       "   262,\n",
       "   717,\n",
       "   4314,\n",
       "   764,\n",
       "   5211,\n",
       "   345,\n",
       "   1612,\n",
       "   326,\n",
       "   314,\n",
       "   467,\n",
       "   326,\n",
       "   835,\n",
       "   329,\n",
       "   530,\n",
       "   2512,\n",
       "   837,\n",
       "   788,\n",
       "   1210,\n",
       "   826,\n",
       "   5633,\n",
       "   5297,\n",
       "   837,\n",
       "   345,\n",
       "   389,\n",
       "   826,\n",
       "   764,\n",
       "   3792,\n",
       "   340,\n",
       "   1290,\n",
       "   5633,\n",
       "   2949,\n",
       "   837,\n",
       "   632,\n",
       "   338,\n",
       "   691,\n",
       "   546,\n",
       "   1936,\n",
       "   2431,\n",
       "   705,\n",
       "   2513,\n",
       "   764,\n",
       "   10449,\n",
       "   345,\n",
       "   845,\n",
       "   881,\n",
       "   764,\n",
       "   50256,\n",
       "   1026,\n",
       "   338,\n",
       "   616,\n",
       "   9476,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   1026,\n",
       "   338,\n",
       "   616,\n",
       "   9476,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 99},\n",
       " {'input_ids': [23722,\n",
       "   345,\n",
       "   1577,\n",
       "   502,\n",
       "   617,\n",
       "   5608,\n",
       "   319,\n",
       "   703,\n",
       "   284,\n",
       "   2222,\n",
       "   510,\n",
       "   616,\n",
       "   3367,\n",
       "   6105,\n",
       "   5633,\n",
       "   1544,\n",
       "   338,\n",
       "   257,\n",
       "   6016,\n",
       "   2933,\n",
       "   837,\n",
       "   2125,\n",
       "   470,\n",
       "   339,\n",
       "   5633,\n",
       "   1537,\n",
       "   339,\n",
       "   1464,\n",
       "   266,\n",
       "   320,\n",
       "   862,\n",
       "   503,\n",
       "   286,\n",
       "   8722,\n",
       "   764,\n",
       "   50256,\n",
       "   3987,\n",
       "   470,\n",
       "   5490,\n",
       "   837,\n",
       "   339,\n",
       "   1183,\n",
       "   787,\n",
       "   922,\n",
       "   4371,\n",
       "   2239,\n",
       "   416,\n",
       "   2239,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   3987,\n",
       "   470,\n",
       "   5490,\n",
       "   837,\n",
       "   339,\n",
       "   1183,\n",
       "   787,\n",
       "   922,\n",
       "   4371,\n",
       "   2239,\n",
       "   416,\n",
       "   2239,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 49},\n",
       " {'input_ids': [40,\n",
       "   1101,\n",
       "   287,\n",
       "   2026,\n",
       "   22,\n",
       "   764,\n",
       "   314,\n",
       "   423,\n",
       "   257,\n",
       "   1178,\n",
       "   2761,\n",
       "   351,\n",
       "   616,\n",
       "   2119,\n",
       "   764,\n",
       "   2061,\n",
       "   318,\n",
       "   326,\n",
       "   1917,\n",
       "   837,\n",
       "   15967,\n",
       "   5633,\n",
       "   1858,\n",
       "   389,\n",
       "   7540,\n",
       "   305,\n",
       "   3694,\n",
       "   287,\n",
       "   616,\n",
       "   2119,\n",
       "   764,\n",
       "   8491,\n",
       "   345,\n",
       "   1654,\n",
       "   837,\n",
       "   15967,\n",
       "   5633,\n",
       "   1610,\n",
       "   444,\n",
       "   314,\n",
       "   714,\n",
       "   1975,\n",
       "   837,\n",
       "   475,\n",
       "   7540,\n",
       "   305,\n",
       "   3694,\n",
       "   5633,\n",
       "   40,\n",
       "   1053,\n",
       "   14789,\n",
       "   5193,\n",
       "   1180,\n",
       "   7540,\n",
       "   305,\n",
       "   3694,\n",
       "   837,\n",
       "   290,\n",
       "   314,\n",
       "   14716,\n",
       "   10764,\n",
       "   319,\n",
       "   1194,\n",
       "   530,\n",
       "   764,\n",
       "   22788,\n",
       "   837,\n",
       "   356,\n",
       "   1057,\n",
       "   257,\n",
       "   4136,\n",
       "   1203,\n",
       "   290,\n",
       "   7540,\n",
       "   28562,\n",
       "   12,\n",
       "   1203,\n",
       "   7541,\n",
       "   764,\n",
       "   1639,\n",
       "   16498,\n",
       "   284,\n",
       "   4719,\n",
       "   502,\n",
       "   5633,\n",
       "   50256,\n",
       "   40,\n",
       "   1101,\n",
       "   7926,\n",
       "   837,\n",
       "   15967,\n",
       "   764,\n",
       "   3914,\n",
       "   502,\n",
       "   4351,\n",
       "   345,\n",
       "   284,\n",
       "   616,\n",
       "   21277,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   40,\n",
       "   1101,\n",
       "   7926,\n",
       "   837,\n",
       "   15967,\n",
       "   764,\n",
       "   3914,\n",
       "   502,\n",
       "   4351,\n",
       "   345,\n",
       "   284,\n",
       "   616,\n",
       "   21277,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 100},\n",
       " {'input_ids': [40127,\n",
       "   1904,\n",
       "   502,\n",
       "   837,\n",
       "   15967,\n",
       "   837,\n",
       "   314,\n",
       "   1101,\n",
       "   7787,\n",
       "   345,\n",
       "   460,\n",
       "   470,\n",
       "   3952,\n",
       "   534,\n",
       "   1097,\n",
       "   994,\n",
       "   764,\n",
       "   5195,\n",
       "   407,\n",
       "   5633,\n",
       "   632,\n",
       "   338,\n",
       "   616,\n",
       "   7647,\n",
       "   2272,\n",
       "   764,\n",
       "   40,\n",
       "   1101,\n",
       "   7787,\n",
       "   407,\n",
       "   837,\n",
       "   15967,\n",
       "   764,\n",
       "   5812,\n",
       "   5633,\n",
       "   1320,\n",
       "   338,\n",
       "   257,\n",
       "   5975,\n",
       "   764,\n",
       "   3914,\n",
       "   502,\n",
       "   766,\n",
       "   2644,\n",
       "   360,\n",
       "   8702,\n",
       "   1157,\n",
       "   3954,\n",
       "   3290,\n",
       "   338,\n",
       "   10955,\n",
       "   764,\n",
       "   3363,\n",
       "   837,\n",
       "   314,\n",
       "   1101,\n",
       "   1654,\n",
       "   428,\n",
       "   616,\n",
       "   7647,\n",
       "   2272,\n",
       "   5145,\n",
       "   1537,\n",
       "   314,\n",
       "   2497,\n",
       "   257,\n",
       "   2266,\n",
       "   1097,\n",
       "   1464,\n",
       "   7647,\n",
       "   994,\n",
       "   878,\n",
       "   764,\n",
       "   5812,\n",
       "   837,\n",
       "   356,\n",
       "   1053,\n",
       "   655,\n",
       "   1128,\n",
       "   14215,\n",
       "   674,\n",
       "   1097,\n",
       "   764,\n",
       "   632,\n",
       "   373,\n",
       "   2266,\n",
       "   764,\n",
       "   13300,\n",
       "   764,\n",
       "   887,\n",
       "   262,\n",
       "   1097,\n",
       "   286,\n",
       "   428,\n",
       "   2272,\n",
       "   468,\n",
       "   257,\n",
       "   5445,\n",
       "   8286,\n",
       "   1177,\n",
       "   10162,\n",
       "   319,\n",
       "   262,\n",
       "   1364,\n",
       "   764,\n",
       "   10995,\n",
       "   764,\n",
       "   632,\n",
       "   973,\n",
       "   284,\n",
       "   764,\n",
       "   775,\n",
       "   1392,\n",
       "   326,\n",
       "   5969,\n",
       "   7415,\n",
       "   1165,\n",
       "   764,\n",
       "   23722,\n",
       "   345,\n",
       "   4043,\n",
       "   329,\n",
       "   257,\n",
       "   5664,\n",
       "   837,\n",
       "   15967,\n",
       "   5633,\n",
       "   314,\n",
       "   1549,\n",
       "   588,\n",
       "   284,\n",
       "   423,\n",
       "   257,\n",
       "   2198,\n",
       "   764,\n",
       "   19457,\n",
       "   837,\n",
       "   467,\n",
       "   4058,\n",
       "   764,\n",
       "   14385,\n",
       "   837,\n",
       "   15967,\n",
       "   837,\n",
       "   616,\n",
       "   7457,\n",
       "   764,\n",
       "   770,\n",
       "   318,\n",
       "   534,\n",
       "   7647,\n",
       "   2272,\n",
       "   764,\n",
       "   50256,\n",
       "   2504,\n",
       "   338,\n",
       "   477,\n",
       "   826,\n",
       "   764,\n",
       "   632,\n",
       "   338,\n",
       "   407,\n",
       "   534,\n",
       "   8046,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   2504,\n",
       "   338,\n",
       "   477,\n",
       "   826,\n",
       "   764,\n",
       "   632,\n",
       "   338,\n",
       "   407,\n",
       "   534,\n",
       "   8046,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 165},\n",
       " {'input_ids': [2061,\n",
       "   460,\n",
       "   314,\n",
       "   466,\n",
       "   329,\n",
       "   345,\n",
       "   1909,\n",
       "   5633,\n",
       "   40,\n",
       "   761,\n",
       "   284,\n",
       "   2822,\n",
       "   257,\n",
       "   649,\n",
       "   30500,\n",
       "   1909,\n",
       "   764,\n",
       "   35653,\n",
       "   345,\n",
       "   2045,\n",
       "   379,\n",
       "   257,\n",
       "   1948,\n",
       "   30500,\n",
       "   5633,\n",
       "   40,\n",
       "   588,\n",
       "   326,\n",
       "   7148,\n",
       "   3549,\n",
       "   30500,\n",
       "   764,\n",
       "   1212,\n",
       "   1948,\n",
       "   30500,\n",
       "   318,\n",
       "   257,\n",
       "   845,\n",
       "   922,\n",
       "   3572,\n",
       "   764,\n",
       "   24446,\n",
       "   502,\n",
       "   546,\n",
       "   340,\n",
       "   764,\n",
       "   3673,\n",
       "   691,\n",
       "   318,\n",
       "   340,\n",
       "   10935,\n",
       "   837,\n",
       "   475,\n",
       "   340,\n",
       "   2058,\n",
       "   351,\n",
       "   477,\n",
       "   262,\n",
       "   29834,\n",
       "   764,\n",
       "   2061,\n",
       "   389,\n",
       "   262,\n",
       "   29834,\n",
       "   764,\n",
       "   1026,\n",
       "   468,\n",
       "   281,\n",
       "   4771,\n",
       "   16009,\n",
       "   837,\n",
       "   1660,\n",
       "   18905,\n",
       "   263,\n",
       "   837,\n",
       "   290,\n",
       "   6088,\n",
       "   286,\n",
       "   2119,\n",
       "   319,\n",
       "   262,\n",
       "   2641,\n",
       "   764,\n",
       "   40,\n",
       "   1549,\n",
       "   588,\n",
       "   284,\n",
       "   766,\n",
       "   340,\n",
       "   329,\n",
       "   3589,\n",
       "   764,\n",
       "   5247,\n",
       "   826,\n",
       "   4058,\n",
       "   764,\n",
       "   50256,\n",
       "   40,\n",
       "   588,\n",
       "   644,\n",
       "   314,\n",
       "   766,\n",
       "   764],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   40,\n",
       "   588,\n",
       "   644,\n",
       "   314,\n",
       "   766,\n",
       "   764,\n",
       "   50256],\n",
       "  'input_len': 103},\n",
       " {'input_ids': [5812,\n",
       "   837,\n",
       "   880,\n",
       "   764,\n",
       "   632,\n",
       "   373,\n",
       "   1257,\n",
       "   284,\n",
       "   307,\n",
       "   262,\n",
       "   8464,\n",
       "   764,\n",
       "   887,\n",
       "   2644,\n",
       "   340,\n",
       "   338,\n",
       "   1165,\n",
       "   1263,\n",
       "   764,\n",
       "   314,\n",
       "   1276,\n",
       "   307,\n",
       "   281,\n",
       "   3131,\n",
       "   1402,\n",
       "   287,\n",
       "   262,\n",
       "   1829,\n",
       "   764,\n",
       "   2396,\n",
       "   644,\n",
       "   546,\n",
       "   262,\n",
       "   20790,\n",
       "   37391,\n",
       "   5633,\n",
       "   8567,\n",
       "   5145,\n",
       "   632,\n",
       "   338,\n",
       "   4998,\n",
       "   764,\n",
       "   314,\n",
       "   460,\n",
       "   470,\n",
       "   4043,\n",
       "   284,\n",
       "   1949,\n",
       "   340,\n",
       "   503,\n",
       "   5145,\n",
       "   2437,\n",
       "   881,\n",
       "   750,\n",
       "   326,\n",
       "   886,\n",
       "   510,\n",
       "   25894,\n",
       "   345,\n",
       "   5633,\n",
       "   5812,\n",
       "   2644,\n",
       "   1088,\n",
       "   8208,\n",
       "   24780,\n",
       "   764,\n",
       "   317,\n",
       "   22803,\n",
       "   611,\n",
       "   345,\n",
       "   1265,\n",
       "   502,\n",
       "   764,\n",
       "   6803,\n",
       "   379,\n",
       "   262,\n",
       "   4286,\n",
       "   286,\n",
       "   607,\n",
       "   2712,\n",
       "   351,\n",
       "   340,\n",
       "   5145,\n",
       "   10814,\n",
       "   837,\n",
       "   734,\n",
       "   329,\n",
       "   530,\n",
       "   764,\n",
       "   1320,\n",
       "   338,\n",
       "   257,\n",
       "   2208,\n",
       "   1730,\n",
       "   764,\n",
       "   50256,\n",
       "   1870,\n",
       "   994,\n",
       "   338,\n",
       "   607,\n",
       "   9877,\n",
       "   5145],\n",
       "  'position_ids': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'lm_labels': [-1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -1,\n",
       "   1870,\n",
       "   994,\n",
       "   338,\n",
       "   607,\n",
       "   9877,\n",
       "   5145,\n",
       "   50256],\n",
       "  'input_len': 102}]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey man, you wanna buy some weed?Some what?Weed! You know? Pot, Ganja, Mary Jane some chronic!Oh, umm, no thanks.I also have blow if you prefer to do a few lines.No, I am ok, really.Come on man! I even got dope and acid! Try some!Do you really have all of these drugs? Where do you get them from?I got my connections! Just tell me what you want and I ’ ll even give you one ounce for free.Sounds good! Let ’ s see, I want.Yeah?<|endoftext|>I want you to put your hands behind your head! You are under arrest!'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([10814,582,837,345,18869,2822,617,20349,5633,4366,644,5633,1135,276,5145,921,760,5633,6902,837,23207,6592,837,5335,12091,617,10726,5145,5812,837,334,3020,837,645,5176,764,40,635,423,6611,611,345,4702,284,466,257,1178,3951,764,2949,837,314,716,12876,837,1107,764,16773,319,582,5145,314,772,1392,45654,290,7408,5145,9993,617,5145,5211,345,1107,423,477,286,777,5010,5633,6350,466,345,651,606,422,5633,40,1392,616,8787,5145,2329,1560,502,644,345,765,290,314,564,247,32660,772,1577,345,530,25799,329,1479,764,40825,922,5145,3914,564,247,264,766,837,314,765,764,10995,5633,50256,40,765,345,284,1234,534,2832,2157,534,1182,5145,921,389,739,3251,5145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset,collate_fn=GPT2Dataset.collate,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model,train_dataloader,learning_rate,epoches):\n",
    "    \n",
    "    optimizer = Adam(model.parameters(),lr=learning_rate)\n",
    "    step = 0\n",
    "    epoch = 0 \n",
    "    \n",
    "    pbar = tqdm(enumerate(train_dataloader),total=len(train_dataloader))    # 定义进度条，pbar又同时是enumerate后的data_loader对象\n",
    "    loss_function  = CrossEntropyLoss(ignore_index=-1,reduction='mean')\n",
    "    while epoch < epoches:\n",
    "        running_loss = 0\n",
    "        try:\n",
    "            with tqdm(enumerate(train_dataloader),total=len(train_dataloader)) as pbar:\n",
    "                for i,batch in pbar:\n",
    "                    input_ids,position_ids,token_type_ids,label_ids = batch\n",
    "                    '''\n",
    "                    推理函数\n",
    "                    '''\n",
    "                    logits = model(input_ids=input_ids,position_ids=position_ids,token_type_ids=token_type_ids)\n",
    "                    \n",
    "                    lm_logits= logits[0]\n",
    "            \n",
    "                    loss = loss_function(lm_logits.view(-1,lm_logits.size(-1)),label_ids.view(-1))\n",
    "                    running_loss += loss.item()\n",
    "                    pbar.set_description('Train (Epoch{}):{:.4f}'.format(epoch,running_loss/(step+1)))\n",
    "                    optimizer.zero_grad() # dw = 0\n",
    "                    loss.backward()\n",
    "                    optimizer.step() # w = w +dw\n",
    "                    step += 1\n",
    "                epoch += 1\n",
    "        except KeyboardInterrupt:\n",
    "            pbar.close()\n",
    "            raise\n",
    "        pbar.close()\n",
    "    torch.save({'model':model.state_dict(),\n",
    "               'epoch':epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]\n",
      "Train (Epoch0):3.2267: 100%|███████████████████████████████████████████████████████| 1000/1000 [46:58<00:00,  2.82s/it]\n",
      "Train (Epoch1):1.0547: 100%|███████████████████████████████████████████████████████| 1000/1000 [48:11<00:00,  2.89s/it]\n",
      "Train (Epoch2):0.4725: 100%|███████████████████████████████████████████████████████| 1000/1000 [48:06<00:00,  2.89s/it]\n",
      "Train (Epoch3):0.2286: 100%|███████████████████████████████████████████████████████| 1000/1000 [47:57<00:00,  2.88s/it]\n",
      "Train (Epoch4):0.1226: 100%|███████████████████████████████████████████████████████| 1000/1000 [48:06<00:00,  2.89s/it]\n",
      "Train (Epoch5):0.0685: 100%|███████████████████████████████████████████████████████| 1000/1000 [47:59<00:00,  2.88s/it]\n",
      "Train (Epoch6):0.0424: 100%|███████████████████████████████████████████████████████| 1000/1000 [47:53<00:00,  2.87s/it]\n",
      "Train (Epoch7):0.0296: 100%|███████████████████████████████████████████████████████| 1000/1000 [48:06<00:00,  2.89s/it]\n",
      "Train (Epoch8):0.0228: 100%|███████████████████████████████████████████████████████| 1000/1000 [48:09<00:00,  2.89s/it]\n",
      "Train (Epoch9):0.0171: 100%|███████████████████████████████████████████████████████| 1000/1000 [48:40<00:00,  2.92s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save() missing 1 required positional argument: 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-280-eae72768be66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-258-e564a3340932>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(model, train_dataloader, learning_rate, epoches)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     torch.save({'model':model.state_dict(),\n\u001b[1;32m---> 35\u001b[1;33m                'epoch':epoch})\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: save() missing 1 required positional argument: 'f'"
     ]
    }
   ],
   "source": [
    "run(model,loader,1e-4,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试语句 \n",
    "一轮对话   \n",
    "1. Does money buy happiness ?   \n",
    "2. What is the best way to buy happiness?   \n",
    "\n",
    "一轮对话   \n",
    "1. what is the meaning of a godd life ?   \n",
    "2. How to be a good person ?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(string, eot=True):\n",
    "    '''\n",
    "    encode a string into ids\n",
    "    '''\n",
    "    inputs = tokenizer.encode(eot and string + \"<|endoftext|>\" or string) # sum的start参数可以作为一个起始类型，[]则代表列表相加\n",
    "#                 lm_labels = [-1]*len(inputs) + tokenizer.encode(dial[-1] + end_text) \n",
    "    token_type_ids = [0] * len(inputs)\n",
    "    input_ids = inputs\n",
    "#                 input_len = len(input_ids)\n",
    "    position_ids = list(range(len(input_ids)))\n",
    "    \n",
    "#     print(input_ids,position_ids,token_type_ids)\n",
    "    \n",
    "    input_ids = pad_sequence([torch.tensor(input_ids, dtype=torch.long)], batch_first=True, padding_value=0)\n",
    "    position_ids = pad_sequence([torch.tensor(position_ids, dtype=torch.long)], batch_first=True, padding_value=0)\n",
    "    token_type_ids = pad_sequence([torch.tensor(token_type_ids, dtype=torch.long)], batch_first=True, padding_value=0)\n",
    "#     labels = pad_sequence([torch.tensor(f['lm_labels'], dtype=torch.long)\n",
    "#                           for f in features],batch_first=True,padding_value=-1)\n",
    "    return input_ids, position_ids, token_type_ids\n",
    "\n",
    "def inference(text, model=model, eot=True):\n",
    "    \n",
    "    encoded = enc(text, eot=eot)\n",
    "    \n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=encoded[0], position_ids=encoded[1], token_type_ids=encoded[2])\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    # get the predicted words\n",
    "    predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "    print(encoded[0].tolist())\n",
    "    predicted_text = tokenizer.decode([predicted_index])\n",
    "    \n",
    "    return predicted_text\n",
    "\n",
    "def get_answer(text):\n",
    "    ans = \"\"\n",
    "    next_word = inference(text)\n",
    "    ans += \"<|endoftext|>\"\n",
    "    ans += next_word\n",
    "    while next_word not in [\",\", \".\", \"!\", \"?\"]:\n",
    "        next_word = inference(text+ans, eot=False)\n",
    "        ans += next_word\n",
    "    return ans.strip(\"<|endoftext|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13921, 1637, 2822, 12157, 5633, 50256]]\n",
      "[[13921, 1637, 2822, 12157, 5633, 50256, 3237]]\n",
      "[[13921, 1637, 2822, 12157, 5633, 50256, 3237, 826]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All right.'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"Does money buy happiness ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061, 318]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061, 318, 262]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061, 318, 262, 1266]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061, 318, 262, 1266, 835]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061, 318, 262, 1266, 835, 284]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061, 318, 262, 1266, 835, 284, 4341]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061, 318, 262, 1266, 835, 284, 4341, 257]]\n",
      "[[2061, 318, 262, 1266, 835, 284, 2822, 12157, 30, 50256, 2061, 318, 262, 1266, 835, 284, 4341, 257, 1110]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the best way to spend a day.'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"What is the best way to buy happiness?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40, 892]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40, 892, 257]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40, 892, 257, 922]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40, 892, 257, 922, 1204]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40, 892, 257, 922, 1204, 318]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40, 892, 257, 922, 1204, 318, 257]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40, 892, 257, 922, 1204, 318, 257, 922]]\n",
      "[[10919, 318, 262, 3616, 286, 257, 922, 1204, 5633, 50256, 40, 892, 257, 922, 1204, 318, 257, 922, 530]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I think a good life is a good one.'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"what is the meaning of a good life ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2437, 284, 307, 257, 922, 1048, 5633, 50256]]\n",
      "[[2437, 284, 307, 257, 922, 1048, 5633, 50256, 40]]\n",
      "[[2437, 284, 307, 257, 922, 1048, 5633, 50256, 40, 716]]\n",
      "[[2437, 284, 307, 257, 922, 1048, 5633, 50256, 40, 716, 5410]]\n",
      "[[2437, 284, 307, 257, 922, 1048, 5633, 50256, 40, 716, 5410, 319]]\n",
      "[[2437, 284, 307, 257, 922, 1048, 5633, 50256, 40, 716, 5410, 319, 5033]]\n",
      "[[2437, 284, 307, 257, 922, 1048, 5633, 50256, 40, 716, 5410, 319, 5033, 257]]\n",
      "[[2437, 284, 307, 257, 922, 1048, 5633, 50256, 40, 716, 5410, 319, 5033, 257, 1365]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am planning on becoming a better.'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"How to be a good person ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
