{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本周只有一个代码实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <评阅点>     \n",
    "1. 完成代码并无bug  50‘   \n",
    "2. 代码有部分bug   40'   \n",
    "3. 代码有重大bug   30‘\n",
    "4. 代码不完整  20'   \n",
    "5. 其余 0‘   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码课用来加载 预先训练好的模型,你需要只需要修改模型的存放路径即可（第二行代码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步 使用以下链接下载相应预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://convaisharables.blob.core.windows.net/lsp/multiref/small_ft.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "weights = torch.load('../../../test.pkl')\n",
    "medium_config = GPT2Config(n_embd = 768,n_layer = 12, n_head = 12)\n",
    "model = GPT2LMHeadModel(medium_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"lm_head.weight\" in weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(weights)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你需要写一个推理函数，这个函数接收一个英文句子为输入，输出一个回应。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次作业需要用beam search+k sampling输出随机值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试语句 \n",
    "一轮对话   \n",
    "1. Does money buy happiness ?   \n",
    "2. What is the best way to buy happiness?   \n",
    "\n",
    "一轮对话   \n",
    "1. what is the meaning of a godd life ?   \n",
    "2. How to be a good person ?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(string, eot=True):\n",
    "    '''\n",
    "    encode a string into ids\n",
    "    '''\n",
    "    inputs = tokenizer.encode(eot and string + \"<|endoftext|>\" or string) # sum的start参数可以作为一个起始类型，[]则代表列表相加\n",
    "#                 lm_labels = [-1]*len(inputs) + tokenizer.encode(dial[-1] + end_text) \n",
    "    token_type_ids = [0] * len(inputs)\n",
    "    input_ids = inputs\n",
    "#                 input_len = len(input_ids)\n",
    "    position_ids = list(range(len(input_ids)))\n",
    "    \n",
    "#     print(input_ids,position_ids,token_type_ids)\n",
    "    \n",
    "    input_ids = pad_sequence([torch.tensor(input_ids, dtype=torch.long)], batch_first=True, padding_value=0)\n",
    "    position_ids = pad_sequence([torch.tensor(position_ids, dtype=torch.long)], batch_first=True, padding_value=0)\n",
    "    token_type_ids = pad_sequence([torch.tensor(token_type_ids, dtype=torch.long)], batch_first=True, padding_value=0)\n",
    "#     labels = pad_sequence([torch.tensor(f['lm_labels'], dtype=torch.long)\n",
    "#                           for f in features],batch_first=True,padding_value=-1)\n",
    "    return input_ids, position_ids, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   40,   423,   257,  3112,    13, 50256]]),\n",
       " tensor([[0, 1, 2, 3, 4, 5]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = enc('I have a pen.')\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=encoded[0], position_ids=encoded[1], token_type_ids=encoded[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50257])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape # outputs的第一个tuple，由于GPT2是自回归模型，所以，输入6输出也是6，但是所有的都往左位移了一格，然后最后一个输出是predicted value，然后每个词都是50257维的one-hot向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_logits= outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 19.1266,  15.3958,  14.7983,  ...,  16.8080,  15.6083,  18.9024],\n",
       "         [ -5.1786,  -7.3125, -15.0115,  ..., -10.5633,  -7.2009,  -4.3034],\n",
       "         [ -3.0187,   1.3590,  -2.7922,  ...,  -4.9838,  -1.0575,   1.2865],\n",
       "         [ 17.1909,  18.6429,   5.0212,  ...,   4.0638,   6.6532,  26.3990],\n",
       "         [ 24.1390,  16.5694,   7.6491,  ...,   8.3795,   9.2894,  26.2065],\n",
       "         [ 29.9232,  24.9513,  11.7002,  ...,  11.6995,   9.9057,  32.7579]]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19.1266, 15.3958, 14.7983,  ..., 11.6995,  9.9057, 32.7579]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits.view(-1,301542)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_function(lm_logits.view(-1,lm_logits.size(-1)), label_ids.view(-1))\n",
    "running_loss += loss.item()\n",
    "pbar.set_description('Train (Epoch{}):{:.4f}'.format(epoch,running_loss/(step+1)))\n",
    "optimizer.zero_grad() # dw = 0\n",
    "loss.backward()\n",
    "optimizer.step() # w = w +dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29.9232, 24.9513, 11.7002,  ..., 11.6995,  9.9057, 32.7579])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][0,-1,:] # 这个就是输出词的每个position的预测值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.3726e-07, 3.0303e-09, 5.3282e-15,  ..., 5.3247e-15, 8.8568e-16,\n",
       "        7.4444e-06])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prb = F.softmax(outputs[0][0,-1,:], dim=-1)\n",
    "prb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.8322, 0.0498, 0.0331, 0.0182, 0.0153, 0.0130, 0.0107, 0.0039, 0.0034,\n",
       "        0.0030]),\n",
       "indices=tensor([ 2061, 35284,    40,  5756, 12050,  8491,  2504,  3855, 11980,  5812]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.topk(prb, k=10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2061, 'What', 0.8322375416755676),\n",
       " (35284, 'Nice', 0.04978508502244949),\n",
       " (40, 'I', 0.0331263393163681),\n",
       " (5756, 'Let', 0.018214786425232887),\n",
       " (12050, 'Make', 0.015283136628568172),\n",
       " (8491, 'Are', 0.012990733608603477),\n",
       " (2504, 'That', 0.010732457041740417),\n",
       " (3855, 'Get', 0.0038835557643324137),\n",
       " (11980, 'Have', 0.003393117105588317),\n",
       " (5812, 'Oh', 0.0030398769304156303)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i.item(), j, k.item()) for i, j, k in zip(a.indices, [tokenizer.decode([i]) for i in a.indices], a.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为此我们需要写一个新的推理函数，inference_with_k_sampling(),它输出k个结果，每个结果都同时输出其概率值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_with_k_sampling(text, model=model, eot=True, k=10):\n",
    "    '''\n",
    "    return: list of (index, text, prob)\n",
    "    '''\n",
    "    encoded = enc(text, eot=eot)\n",
    "    \n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=encoded[0], position_ids=encoded[1], token_type_ids=encoded[2])\n",
    "        predictions = outputs[0]\n",
    "    \n",
    "    # get the predicted words\n",
    "    top_k = torch.topk(F.softmax(predictions[0, -1, :], dim=-1), k=k)\n",
    "    \n",
    "    #print(encoded[0].tolist())\n",
    "#     predicted_text = tokenizer.decode([predicted_index])\n",
    "    \n",
    "    return [(i.item(), j, k.item()) for i, j, k in zip(top_k.indices, [tokenizer.decode([i]) for i in top_k.indices], top_k.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5297, 'Yes', 0.5281760692596436),\n",
       " (1026, 'It', 0.31469130516052246),\n",
       " (2949, 'No', 0.08707515895366669),\n",
       " (19457, 'Sure', 0.016037512570619583),\n",
       " (464, 'The', 0.010043371468782425),\n",
       " (40, 'I', 0.008420667611062527),\n",
       " (1639, 'You', 0.007362084928900003),\n",
       " (2061, 'What', 0.007030633743852377),\n",
       " (2504, 'That', 0.0059713758528232574),\n",
       " (1858, 'There', 0.0034675351344048977)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_with_k_sampling(\"Does money buy happiness ?\", eot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_answer_2(text, sort=True, random1=True):\n",
    "    def generate_until(input_string, prob):\n",
    "        '''\n",
    "        input_: 初始词\n",
    "        prob: 概率\n",
    "        \n",
    "        输出：生成直到，！？的句子，以及其概率\n",
    "        '''\n",
    "        next_ = inference_with_k_sampling(text+\"<|endoftext|>\"+input_string, k=1, eot=False)\n",
    "        ans = input_string + next_[0][1]\n",
    "        cache = text+\"<|endoftext|>\"+ans\n",
    "        prob *= next_[0][2]\n",
    "        i = 0\n",
    "        while next_[0][1] not in [\".\", \"!\", \"?\", \"<|endoftext|>\"] and i<=30:\n",
    "            next_ = inference_with_k_sampling(cache, k=1, eot=False)\n",
    "            ans += next_[0][1]\n",
    "            cache += ans\n",
    "            prob *= next_[0][2]\n",
    "#             print()\n",
    "            i+=1\n",
    "            \n",
    "        return ans, prob\n",
    "\n",
    "    next_list = inference_with_k_sampling(text, k=10)\n",
    "#     print(next_list)\n",
    "    candidate_dict = {i:(j[1], j[2]) for i, j in zip(range(10), next_list)}\n",
    "#     print(candidate_dict)\n",
    "    for _, (candidate, prob) in candidate_dict.items():\n",
    "#         print(_, candidate, prob)\n",
    "        candidate_dict[_] = generate_until(candidate, prob)\n",
    "#         print(\"\")\n",
    "#     print(candidate_dict)\n",
    "    if random1: return random.choice([k for k, v in candidate_dict.values()])\n",
    "    if sort: return sorted([v for k, v in candidate_dict.items()], key=lambda x: x[1], reverse = True) \n",
    "    else: return candidate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is a little problem between us.'"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_2(\"Does money buy happiness ? \", random1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"It's about time.\", 0.11723031567650749),\n",
       " ('Sure.', 0.014506726515711721),\n",
       " ('The real question is whether or not.', 0.00883955673314908),\n",
       " ('I think so.', 0.002488113462639314),\n",
       " ('You can bet on that.', 0.0017246795944729503),\n",
       " ('Yes,It is a good investment in my company.', 0.0012018644527898707),\n",
       " (\"No,It's just about money.\", 0.0010512966587768696),\n",
       " ('There is a little problem between us.', 9.872700070003716e-05),\n",
       " ('What is the money is the problem?', 9.6869360925509e-05),\n",
       " (\"That's what's wrong between us and the world economy.\",\n",
       "  6.430478345778175e-05)]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_2(\"Does money buy happiness ? \", random1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The best way to do is by doing a series of activities.'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_2(\"What is the best way to buy happiness?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I think so.', 0.15229214501080376),\n",
       " ('Yeah, I am totally jealous.', 0.03530705868327192),\n",
       " ('No, not at all.', 0.02419013760133699),\n",
       " ('Yes, I am totally jealous.', 0.010504114550062883),\n",
       " ('Sure.', 0.010056214718612955),\n",
       " ('Not too bad.', 0.0061387063823353785),\n",
       " (\"It's not too hot in the north.\", 0.0029501480398664765),\n",
       " (\"He wouldn't say over the phone.\", 0.0007436986985838966),\n",
       " ('Well, I think I am quite qualified to be a good person.',\n",
       "  0.00031363171348342575),\n",
       " ('You mean I have a little problem, too.', 0.000119927872940365)]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_2(\"How to be a good person ?\", random1=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**多轮对话测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is the best way to do I choose a political party?',\n",
       "  0.07390050771820343),\n",
       " ('No, not at all.', 0.0007391414922646724),\n",
       " (\"That's a good idea.\", 0.0005343041367944348),\n",
       " ('How are you these days?', 0.0002441910196466721),\n",
       " (\"It's not too easy to do that.\", 0.00023806249608195073),\n",
       " ('Why not go and find a way to make a positive change in yourself?',\n",
       "  0.0002229447967719199),\n",
       " ('Of course not.', 0.00021850619759496192),\n",
       " ('You can do that by subscribing a member of a political party.',\n",
       "  6.382103524128901e-05),\n",
       " ('I see, therefore, therefore, therefore, therefore, therefore, therefore, therefore, therefore, therefore, therefore, therefore, therefore, therefore, therefore, therefore,',\n",
       "  4.4271453947673446e-06),\n",
       " ('Yes, therefore, therefore, therefore, therefore, therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore therefore',\n",
       "  1.754968687273734e-06)]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_2(\"What is the best way to buy happiness? You can do it by subscribing a member of a local political party. I don't like that. \", random1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('No problem.', 0.002888295467295442),\n",
       " ('Another tough thing,I guess.', 0.0008201926648499017),\n",
       " ('Not too bad.', 0.0005940972785012672),\n",
       " ('Oh, I am really sorry.', 0.000521145289975079),\n",
       " ('You are the expert on it.', 0.0004488264412821989),\n",
       " (\"Don't mention it.\", 0.00042215233474722464),\n",
       " ('Who are you?', 0.00041752036576342535),\n",
       " (\"It's a private company.\", 0.00014159483106282323),\n",
       " (\"I'm a professional professional to be a professional to be a professional to be a professional to be professional to be professional to be professional to be professional to be professional to\",\n",
       "  4.889463345459368e-05),\n",
       " ('My name is Johnny.', 4.304059529572206e-05)]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_2(\"Who are you?\", random1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Hello,What ' s up?\", 0.4223702928728857),\n",
       " ('Nice to meet you.', 0.07200017224304393),\n",
       " ('What are you?', 0.04525533364288391),\n",
       " ('Sure.', 0.007596395685389001),\n",
       " (\"Oh,Hello,What ' s up?\", 0.004034367902141518),\n",
       " (\"Yes,Hello,What ' s up?\", 0.0006309761179009532),\n",
       " ('You are the man.', 0.0006262084133798078),\n",
       " ('I am glad to help you.', 0.000546376512814784),\n",
       " (\"Let's see... my ID card,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes\",\n",
       "  9.58623625530295e-05),\n",
       " ('Another tough thing,to say the opposite of the opposite.',\n",
       "  7.538427808150743e-06)]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_2(\"Who are you? My name is Johnny. Hi Johnny!\", random1=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
